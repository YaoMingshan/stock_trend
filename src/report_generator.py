"""
æŠ¥å‘Šç”Ÿæˆæ¨¡å— - è´Ÿè´£ç”ŸæˆJSONæ•°æ®æ–‡ä»¶ä¾›å‰ç«¯ä½¿ç”¨
"""
import json
from pathlib import Path
from typing import Dict
import logging

from .config import DOCS_DATA_DIR, ANALYSIS_DIR, get_china_now

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨ - ç”Ÿæˆå‰ç«¯æ‰€éœ€çš„JSONæ•°æ®æ–‡ä»¶"""
    
    def __init__(self):
        self._ensure_dirs()
    
    def _ensure_dirs(self):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        DOCS_DATA_DIR.mkdir(parents=True, exist_ok=True)
        ANALYSIS_DIR.mkdir(parents=True, exist_ok=True)
    
    def generate_report(self, analysis_result: Dict) -> bool:
        """
        ç”ŸæˆæŠ¥å‘Šï¼ˆJSONæ•°æ®æ–‡ä»¶ï¼‰
        
        Args:
            analysis_result: åˆ†æç»“æœå­—å…¸
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # 1. ä¿å­˜ä¸ºå‰ç«¯ä½¿ç”¨çš„æœ€æ–°æ•°æ®
            self._save_latest_data(analysis_result)
            
            # 2. ä¿å­˜å†å²å­˜æ¡£
            self._save_history_data(analysis_result)
            
            logger.info("âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return False
    
    def _save_latest_data(self, data: Dict):
        """
        ä¿å­˜æœ€æ–°æ•°æ®ä¸ºJSONæ–‡ä»¶ï¼ˆä¾›å‰ç«¯è¯»å–ï¼‰
        æ–‡ä»¶è·¯å¾„: docs/data/latest.json
        """
        latest_path = DOCS_DATA_DIR / "latest.json"
        
        with open(latest_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“„ æœ€æ–°æ•°æ®å·²ä¿å­˜: {latest_path}")
    
    def _save_history_data(self, data: Dict):
        """
        ä¿å­˜å†å²æ•°æ®å­˜æ¡£
        æ–‡ä»¶è·¯å¾„: 
          - docs/data/data_YYYY-MM-DD.json (ä¾›å‰ç«¯å†å²æŸ¥è¯¢)
          - data/analysis/analysis_YYYY-MM-DD.json (æœ¬åœ°å­˜æ¡£)
        """
        date_str = data.get('analysis_date', get_china_now().strftime('%Y-%m-%d'))
        
        # ä¿å­˜åˆ° docs/data ç›®å½•ï¼ˆå‰ç«¯å¯è®¿é—®ï¼‰
        frontend_history_path = DOCS_DATA_DIR / f"data_{date_str}.json"
        with open(frontend_history_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜åˆ° data/analysis ç›®å½•ï¼ˆæœ¬åœ°å­˜æ¡£ï¼‰
        local_history_path = ANALYSIS_DIR / f"analysis_{date_str}.json"
        with open(local_history_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“š å†å²æ•°æ®å·²ä¿å­˜: {date_str}")
    
    def clean_old_history(self, keep_days: int = 30):
        """
        æ¸…ç†æ—§çš„å†å²æ•°æ®ï¼ˆå¯é€‰ï¼‰
        
        Args:
            keep_days: ä¿ç•™æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®
        """
        import os
        from datetime import datetime, timedelta
        
        cutoff_date = get_china_now() - timedelta(days=keep_days)
        
        # æ¸…ç† docs/data ç›®å½•
        for file_path in DOCS_DATA_DIR.glob("data_*.json"):
            try:
                # ä»æ–‡ä»¶åæå–æ—¥æœŸ
                date_str = file_path.stem.replace("data_", "")
                file_date = datetime.strptime(date_str, "%Y-%m-%d")
                
                if file_date.date() < cutoff_date.date():
                    file_path.unlink()
                    logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§æ–‡ä»¶: {file_path.name}")
                    
            except (ValueError, OSError) as e:
                logger.warning(f"æ¸…ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # æ¸…ç† data/analysis ç›®å½•
        for file_path in ANALYSIS_DIR.glob("analysis_*.json"):
            try:
                date_str = file_path.stem.replace("analysis_", "")
                file_date = datetime.strptime(date_str, "%Y-%m-%d")
                
                if file_date.date() < cutoff_date.date():
                    file_path.unlink()
                    logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§æ–‡ä»¶: {file_path.name}")
                    
            except (ValueError, OSError) as e:
                logger.warning(f"æ¸…ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")


def get_available_history_dates() -> list:
    """
    è·å–å¯ç”¨çš„å†å²æ•°æ®æ—¥æœŸåˆ—è¡¨
    
    Returns:
        æ—¥æœŸå­—ç¬¦ä¸²åˆ—è¡¨ï¼ŒæŒ‰æ—¥æœŸé™åºæ’åˆ—
    """
    dates = []
    
    for file_path in DOCS_DATA_DIR.glob("data_*.json"):
        try:
            date_str = file_path.stem.replace("data_", "")
            dates.append(date_str)
        except:
            continue
    
    # æŒ‰æ—¥æœŸé™åºæ’åˆ—
    dates.sort(reverse=True)
    
    return dates